{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Processing jobs\n",
    "\n",
    "*이 노트북은 [Amazon SageMaker Processing jobs (영문 원본)](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker_processing/scikit_learn_data_processing_and_model_evaluation/scikit_learn_data_processing_and_model_evaluation.ipynb) 의 한국어 번역입니다.*\n",
    "\n",
    "Amazon SageMaker Processing 작업을 사용하면 간소화된 관리 환경을 활용하여 Amazon SageMaker 플랫폼에서 데이터 전처리&후처리 및 모델 검증 워크로드를 실행할 수 있습니다.\n",
    "\n",
    "Processing 작업은 Amazon Simple Storage Service(Amazon S3)에서 입력 데이터를 다운로드한 다음, processing 작업 중 또는 processing 후 출력 결과를 Amazon S3에 업로드합니다.\n",
    "\n",
    "<img src=\"Processing-1.jpg\">\n",
    "\n",
    "이 노트북은 아래 4가지 작업들을 수행하는 법을 보여줍니다.\n",
    "\n",
    "1. Processing 작업을 실행하여 scikit-learn 스크립트를 실행하여 정제(cleans), 전처리(pre-processes), feature 엔지니어링을 수행하고 입력 데이터를 학습 및 테스트셋으로 분할\n",
    "2. 전처리된 학습 데이터에서 학습 작업을 실행하여 모델 학습\n",
    "3. 전처리 된 테스트 데이터에서 processing 작업을 실행하여 학습된 모델의 성능을 검증\n",
    "4. 자체 사용자 정의 컨테이너(Your Own Custom Container)를 사용하여 자체 Python 라이브러리 및 종속성으로 processing 작업 실행\n",
    "\n",
    "본 노트북에서 사용된 데이터셋은 [Census-Income KDD Dataset](https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29) 입니다. 이 데이터셋에서 feature를 선택하고 데이터를 정제한 후, 데이터를 학습 알고리즘이 이진 분류(binary classification) 모델을 학습할 수 있는 feature로 변환하고, 데이터를 학습 및 테스트셋으로 분할합니다. 이 작업(task)은 응답자의 연간 소득이 `$50,000`이상인지, 또는 `$50,000` 이하인지 예측하는 이진 분류 문제입니다. 이 데이터셋은 클래스 불균형(class imbalance)이 심하며 대부분의 레코드는 `$50,000` 미만의 소득입니다. 여러분은 로지스틱 회귀 모델(Logistic regression model)을 학습한 후 홀드-아웃(hold-out) 테스트 데이터셋에 대해 모델을 검증하고 각 레이블의 정밀도(Precision), 재현도(recall) 및 F1 점수, 정확도(accuracy) 및 ROC AUC를 포함한 분류 검증 지표(classification evaluation metrics)들을 저장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn 전처리 스크립트를 processing 작업으로 실행하려면, 제공된 scikit-learn 이미지를 사용하여 processing 작업 내에서 스크립트를 실행할 수 있는 `SKLearnProcessor`를 생성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 정제, 전처리 및 feature 엔지니어링에 사용하는 스크립트를 도입하기 전에 데이터셋의 첫 20행을 확인해 보세요. 목표는 소득 범주(`income` category)를 예측하는 것입니다. 선택한 데이터셋의 feature는 연령, 교육, 주요 산업 코드, 노동자 계급, 고용주를 위해 일한 인원, 자본 이득, 자본 손실 및 주식 배당금입니다 (`age`, `education`, `major industry code`, `class of worker`, `num persons worked for employer`, `capital gains`, `capital losses`, and `dividends from stocks`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>class of worker</th>\n",
       "      <th>detailed industry recode</th>\n",
       "      <th>detailed occupation recode</th>\n",
       "      <th>education</th>\n",
       "      <th>wage per hour</th>\n",
       "      <th>enroll in edu inst last wk</th>\n",
       "      <th>marital stat</th>\n",
       "      <th>major industry code</th>\n",
       "      <th>major occupation code</th>\n",
       "      <th>...</th>\n",
       "      <th>country of birth father</th>\n",
       "      <th>country of birth mother</th>\n",
       "      <th>country of birth self</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>own business or self employed</th>\n",
       "      <th>fill inc questionnaire for veteran's admin</th>\n",
       "      <th>veterans benefits</th>\n",
       "      <th>weeks worked in year</th>\n",
       "      <th>year</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Self-employed-not incorporated</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Precision production craft &amp; repair</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10th grade</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Foreign born- Not a citizen of U S</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>Private</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>1200</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Professional specialty</td>\n",
       "      <td>...</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>2</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors degree(BA AB BS)</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Finance insurance and real estate</td>\n",
       "      <td>Executive admin and managerial</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Handlers equip cleaners etc</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47</td>\n",
       "      <td>Local government</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>876</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Education</td>\n",
       "      <td>Adm support including clerical</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Machine operators assmblrs &amp; inspctrs</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                  class of worker  detailed industry recode  \\\n",
       "0   73                  Not in universe                         0   \n",
       "1   58   Self-employed-not incorporated                         4   \n",
       "2   18                  Not in universe                         0   \n",
       "3    9                  Not in universe                         0   \n",
       "4   10                  Not in universe                         0   \n",
       "5   48                          Private                        40   \n",
       "6   42                          Private                        34   \n",
       "7   28                          Private                         4   \n",
       "8   47                 Local government                        43   \n",
       "9   34                          Private                         4   \n",
       "\n",
       "   detailed occupation recode                    education  wage per hour  \\\n",
       "0                           0         High school graduate              0   \n",
       "1                          34   Some college but no degree              0   \n",
       "2                           0                   10th grade              0   \n",
       "3                           0                     Children              0   \n",
       "4                           0                     Children              0   \n",
       "5                          10   Some college but no degree           1200   \n",
       "6                           3   Bachelors degree(BA AB BS)              0   \n",
       "7                          40         High school graduate              0   \n",
       "8                          26   Some college but no degree            876   \n",
       "9                          37   Some college but no degree              0   \n",
       "\n",
       "  enroll in edu inst last wk                      marital stat  \\\n",
       "0            Not in universe                           Widowed   \n",
       "1            Not in universe                          Divorced   \n",
       "2                High school                     Never married   \n",
       "3            Not in universe                     Never married   \n",
       "4            Not in universe                     Never married   \n",
       "5            Not in universe   Married-civilian spouse present   \n",
       "6            Not in universe   Married-civilian spouse present   \n",
       "7            Not in universe                     Never married   \n",
       "8            Not in universe   Married-civilian spouse present   \n",
       "9            Not in universe   Married-civilian spouse present   \n",
       "\n",
       "                  major industry code                   major occupation code  \\\n",
       "0         Not in universe or children                         Not in universe   \n",
       "1                        Construction     Precision production craft & repair   \n",
       "2         Not in universe or children                         Not in universe   \n",
       "3         Not in universe or children                         Not in universe   \n",
       "4         Not in universe or children                         Not in universe   \n",
       "5                       Entertainment                  Professional specialty   \n",
       "6   Finance insurance and real estate          Executive admin and managerial   \n",
       "7                        Construction            Handlers equip cleaners etc    \n",
       "8                           Education          Adm support including clerical   \n",
       "9                        Construction   Machine operators assmblrs & inspctrs   \n",
       "\n",
       "   ... country of birth father country of birth mother country of birth self  \\\n",
       "0  ...           United-States           United-States         United-States   \n",
       "1  ...           United-States           United-States         United-States   \n",
       "2  ...                 Vietnam                 Vietnam               Vietnam   \n",
       "3  ...           United-States           United-States         United-States   \n",
       "4  ...           United-States           United-States         United-States   \n",
       "5  ...             Philippines           United-States         United-States   \n",
       "6  ...           United-States           United-States         United-States   \n",
       "7  ...           United-States           United-States         United-States   \n",
       "8  ...           United-States           United-States         United-States   \n",
       "9  ...           United-States           United-States         United-States   \n",
       "\n",
       "                            citizenship own business or self employed  \\\n",
       "0     Native- Born in the United States                             0   \n",
       "1     Native- Born in the United States                             0   \n",
       "2   Foreign born- Not a citizen of U S                              0   \n",
       "3     Native- Born in the United States                             0   \n",
       "4     Native- Born in the United States                             0   \n",
       "5     Native- Born in the United States                             2   \n",
       "6     Native- Born in the United States                             0   \n",
       "7     Native- Born in the United States                             0   \n",
       "8     Native- Born in the United States                             0   \n",
       "9     Native- Born in the United States                             0   \n",
       "\n",
       "  fill inc questionnaire for veteran's admin  veterans benefits  \\\n",
       "0                            Not in universe                  2   \n",
       "1                            Not in universe                  2   \n",
       "2                            Not in universe                  2   \n",
       "3                            Not in universe                  0   \n",
       "4                            Not in universe                  0   \n",
       "5                            Not in universe                  2   \n",
       "6                            Not in universe                  2   \n",
       "7                            Not in universe                  2   \n",
       "8                            Not in universe                  2   \n",
       "9                            Not in universe                  2   \n",
       "\n",
       "   weeks worked in year  year     income  \n",
       "0                     0    95   - 50000.  \n",
       "1                    52    94   - 50000.  \n",
       "2                     0    95   - 50000.  \n",
       "3                     0    94   - 50000.  \n",
       "4                     0    94   - 50000.  \n",
       "5                    52    95   - 50000.  \n",
       "6                    52    94   - 50000.  \n",
       "7                    30    95   - 50000.  \n",
       "8                    52    95   - 50000.  \n",
       "9                    52    94   - 50000.  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_data = 's3://sagemaker-sample-data-{}/processing/census/census-income.csv'.format(region)\n",
    "df = pd.read_csv(input_data, nrows=10)\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북 셀은 전처리 스크립트가 포함된 `preprocessing.py` 파일을 작성합니다. 스크립트를 업데이트하고 이 셀을 다시 실행하여 `preprocessing.py`를 덮어쓸 수 있습니다. 다음 셀에서 이 이것을 processing 작업으로 실행할 수 있습니다. 이 스크립트에서 여러분은 아래 작업들을 실행할 수 있습니다.\n",
    "\n",
    "* 충돌 데이터(conflicting data)가 있는 중복 행을 제거합니다.\n",
    "* target 변수 `imcome`을 두 개의 레이블만 포함된 열로 변환합니다.\n",
    "* `age` and `num persons worked for employer` 수치형 변수를 binning하여 범주형 변수로 변환합니다.\n",
    "지속적인 자본 이득, 자본 손실 및 주식의 배당 규모를 조정하여 훈련에 적합\n",
    "* 연속형 변수 `capital gains`, `capital losses`, `dividends from stocks`의 스케일을 조정합니다.\n",
    "* 범주형 변수 `education`, `major industry code`, `class of worker`를 인코딩합니다. \n",
    "* 데이터를 학습 및 테스트 데이터셋으로 분할하고 학습 feature 및 레이블과 테스트 feature 및 레이블을 저장합니다.\n",
    "\n",
    "학습 스크립트는 전처리된 학습 feature 및 레이블(label)을 사용하여 모델을 학습하고 검증(evaluation) 스크립트는 학습된 모델과 전처리된 테스트 feature 및 레이블을 사용하여 모델을 검증합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer, KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "columns = ['age', 'education', 'major industry code', 'class of worker', 'num persons worked for employer',\n",
    "           'capital gains', 'capital losses', 'dividends from stocks', 'income']\n",
    "class_labels = [' - 50000.', ' 50000+.']\n",
    "\n",
    "def print_shape(df):\n",
    "    negative_examples, positive_examples = np.bincount(df['income'])\n",
    "    print('Data shape: {}, {} positive examples, {} negative examples'.format(df.shape, positive_examples, negative_examples))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-test-split-ratio', type=float, default=0.3)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print('Received arguments {}'.format(args))\n",
    "\n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', 'census-income.csv')\n",
    "    \n",
    "    print('Reading input data from {}'.format(input_data_path))\n",
    "    df = pd.read_csv(input_data_path)\n",
    "    df = pd.DataFrame(data=df, columns=columns)\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.replace(class_labels, [0, 1], inplace=True)\n",
    "    \n",
    "    negative_examples, positive_examples = np.bincount(df['income'])\n",
    "    print('Data after cleaning: {}, {} positive examples, {} negative examples'.format(df.shape, positive_examples, negative_examples))\n",
    "    \n",
    "    split_ratio = args.train_test_split_ratio\n",
    "    print('Splitting data into train and test sets with ratio {}'.format(split_ratio))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop('income', axis=1), df['income'], test_size=split_ratio, random_state=0)\n",
    "\n",
    "    preprocess = make_column_transformer(\n",
    "        (['age', 'num persons worked for employer'], KBinsDiscretizer(encode='onehot-dense', n_bins=10)),\n",
    "        (['capital gains', 'capital losses', 'dividends from stocks'], StandardScaler()),\n",
    "        (['education', 'major industry code', 'class of worker'], OneHotEncoder(sparse=False))\n",
    "    )\n",
    "    print('Running preprocessing and feature engineering transformations')\n",
    "    train_features = preprocess.fit_transform(X_train)\n",
    "    test_features = preprocess.transform(X_test)\n",
    "    \n",
    "    print('Train data shape after preprocessing: {}'.format(train_features.shape))\n",
    "    print('Test data shape after preprocessing: {}'.format(test_features.shape))\n",
    "    \n",
    "    train_features_output_path = os.path.join('/opt/ml/processing/train', 'train_features.csv')\n",
    "    train_labels_output_path = os.path.join('/opt/ml/processing/train', 'train_labels.csv')\n",
    "    \n",
    "    test_features_output_path = os.path.join('/opt/ml/processing/test', 'test_features.csv')\n",
    "    test_labels_output_path = os.path.join('/opt/ml/processing/test', 'test_labels.csv')\n",
    "    \n",
    "    print('Saving training features to {}'.format(train_features_output_path))\n",
    "    pd.DataFrame(train_features).to_csv(train_features_output_path, header=False, index=False)\n",
    "    \n",
    "    print('Saving test features to {}'.format(test_features_output_path))\n",
    "    pd.DataFrame(test_features).to_csv(test_features_output_path, header=False, index=False)\n",
    "    \n",
    "    print('Saving training labels to {}'.format(train_labels_output_path))\n",
    "    y_train.to_csv(train_labels_output_path, header=False, index=False)\n",
    "    \n",
    "    print('Saving test labels to {}'.format(test_labels_output_path))\n",
    "    y_test.to_csv(test_labels_output_path, header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 스크립트를 processing 작업으로 실행하세요. 간단하게 `SKLearnProcessor.run()` 메소드를 사용하시면 됩니다. `run()` 메소드를 실행할 때 inputs 인자값에 하나의 `ProcessingInput` 인스턴스를 제공해야 하며, `ProcessingInput()`의 `source` 인자값은 Amazon S3의 census(인구 조사) 데이터셋이고 `destination` 인자값은 이 데이터를 읽는 위치입니다 (`/opt/ml/processing/input`). 참고로, processing 컨테이너 내부의 이러한 로컬 경로는 `/opt/ml/processing/`으로 시작해야 합니다.\n",
    "\n",
    "또한 `run()` 메소드의 outputs 인자값에 `ProcessingOutput`를 입력하셔야 합니다. 여기서 `source`는 스크립트가 출력 데이터를 쓰는 경로입니다. 출력의 경우 `destination`은 `s3://sagemaker-<region>-<account_id>/<processing_job_name>/output/<output_name/` 형식에 따라 Amazon SageMaker Python SDK가 생성하는 S3 버킷으로 기본 설정됩니다. 또한 작업이 실행 된 후 이러한 출력 아티팩트를 더 쉽게 검색할 수 있도록 `output_name`에 ProcessingOutputs 값을 제공합니다.\n",
    "\n",
    "마지막으로, `run()` 메소드의 `arguments` 파라메터는 `preprocessing.py` 스크립트의 커맨드라인(command-line) 인자값들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2019-12-06-00-19-04-996\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-sample-data-us-east-1/processing/census/census-income.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-19-04-996/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-19-04-996/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-19-04-996/output/test_data', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      "......................\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mReceived arguments Namespace(train_test_split_ratio=0.2)\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/census-income.csv\u001b[0m\n",
      "\u001b[34mData after cleaning: (68285, 9), 11401 positive examples, 56884 negative examples\u001b[0m\n",
      "\u001b[34mSplitting data into train and test sets with ratio 0.2\u001b[0m\n",
      "\u001b[34mRunning preprocessing and feature engineering transformations\u001b[0m\n",
      "\u001b[34mTrain data shape after preprocessing: (54628, 73)\u001b[0m\n",
      "\u001b[34mTest data shape after preprocessing: (13657, 73)\u001b[0m\n",
      "\u001b[34mSaving training features to /opt/ml/processing/train/train_features.csv\u001b[0m\n",
      "\u001b[34mSaving test features to /opt/ml/processing/test/test_features.csv\u001b[0m\n",
      "\u001b[34mSaving training labels to /opt/ml/processing/train/train_labels.csv\u001b[0m\n",
      "\u001b[34mSaving test labels to /opt/ml/processing/test/test_labels.csv\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(code='preprocessing.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=input_data,\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train'),\n",
    "                               ProcessingOutput(output_name='test_data',\n",
    "                                                source='/opt/ml/processing/test')],\n",
    "                      arguments=['--train-test-split-ratio', '0.2']\n",
    "                     )\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'train_data':\n",
    "        preprocessed_training_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'test_data':\n",
    "        preprocessed_test_data = output['S3Output']['S3Uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 처리가 완료된 feature들(processed features)로 구성된 전처리 작업의 출력을 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (10, 73)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>0.0.2</th>\n",
       "      <th>0.0.3</th>\n",
       "      <th>0.0.4</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0.5</th>\n",
       "      <th>0.0.6</th>\n",
       "      <th>0.0.7</th>\n",
       "      <th>0.0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0.56</th>\n",
       "      <th>0.0.57</th>\n",
       "      <th>0.0.58</th>\n",
       "      <th>0.0.59</th>\n",
       "      <th>0.0.60</th>\n",
       "      <th>1.0.4</th>\n",
       "      <th>0.0.61</th>\n",
       "      <th>0.0.62</th>\n",
       "      <th>0.0.63</th>\n",
       "      <th>0.0.64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0  0.0.1  0.0.2  0.0.3  0.0.4  1.0  0.0.5  0.0.6  0.0.7  0.0.8  ...  \\\n",
       "0  0.0    0.0    0.0    0.0    0.0  0.0    0.0    0.0    0.0    1.0  ...   \n",
       "1  0.0    0.0    0.0    0.0    0.0  1.0    0.0    0.0    0.0    0.0  ...   \n",
       "2  0.0    0.0    0.0    0.0    0.0  0.0    0.0    0.0    1.0    0.0  ...   \n",
       "3  0.0    0.0    1.0    0.0    0.0  0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4  0.0    0.0    0.0    1.0    0.0  0.0    0.0    0.0    0.0    0.0  ...   \n",
       "5  0.0    0.0    0.0    0.0    0.0  0.0    0.0    1.0    0.0    0.0  ...   \n",
       "6  0.0    0.0    0.0    0.0    0.0  1.0    0.0    0.0    0.0    0.0  ...   \n",
       "7  0.0    0.0    0.0    0.0    0.0  0.0    1.0    0.0    0.0    0.0  ...   \n",
       "8  0.0    0.0    0.0    0.0    0.0  0.0    1.0    0.0    0.0    0.0  ...   \n",
       "9  1.0    0.0    0.0    0.0    0.0  0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   0.0.56  0.0.57  0.0.58  0.0.59  0.0.60  1.0.4  0.0.61  0.0.62  0.0.63  \\\n",
       "0     0.0     0.0     0.0     0.0     1.0    0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     1.0     0.0     0.0    0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0    0.0     1.0     0.0     0.0   \n",
       "5     0.0     0.0     0.0     0.0     0.0    0.0     1.0     0.0     0.0   \n",
       "6     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "7     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "8     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "9     1.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "\n",
       "   0.0.64  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "5     0.0  \n",
       "6     0.0  \n",
       "7     0.0  \n",
       "8     0.0  \n",
       "9     0.0  \n",
       "\n",
       "[10 rows x 73 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features = pd.read_csv(preprocessed_training_data + '/train_features.csv', nrows=10)\n",
    "print('Training features shape: {}'.format(training_features.shape))\n",
    "training_features.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using the pre-processed data\n",
    "\n",
    "학습 스크립트 `train.py`를 사용하여 학습 작업을 실행하는 데 사용할 `SKLearn` 인스턴스를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    train_instance_type=\"ml.m5.xlarge\",\n",
    "    role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 스크립트 `train.py`는 학습 데이터에 대한 로지스틱 회귀 모델(logistic regression model)을 학습시키고, 모델을 `/opt/ml/model` 디렉토리에 저장합니다. 이 디렉토리는 Amazon SageMaker가 학습 작업 종료시 S3에 `model.tar.gz` 파일로 압축하여 업로드하는 경로입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    training_data_directory = '/opt/ml/input/data/train'\n",
    "    train_features_data = os.path.join(training_data_directory, 'train_features.csv')\n",
    "    train_labels_data = os.path.join(training_data_directory, 'train_labels.csv')\n",
    "    print('Reading input data')\n",
    "    X_train = pd.read_csv(train_features_data, header=None)\n",
    "    y_train = pd.read_csv(train_labels_data, header=None)\n",
    "\n",
    "    model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "    print('Training LR model')\n",
    "    model.fit(X_train, y_train)\n",
    "    model_output_directory = os.path.join('/opt/ml/model', \"model.joblib\")\n",
    "    print('Saving model to {}'.format(model_output_directory))\n",
    "    joblib.dump(model, model_output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training job using `train.py` on the preprocessed training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 00:23:18 Starting - Starting the training job...\n",
      "2019-12-06 00:23:20 Starting - Launching requested ML instances.........\n",
      "2019-12-06 00:24:55 Starting - Preparing the instances for training...\n",
      "2019-12-06 00:25:40 Downloading - Downloading input data...\n",
      "2019-12-06 00:26:10 Training - Training image download completed. Training in progress..\u001b[34m2019-12-06 00:26:11,247 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2019-12-06 00:26:11,249 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2019-12-06 00:26:11,258 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2019-12-06 00:26:18,658 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2019-12-06 00:26:18,659 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2019-12-06 00:26:18,659 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2019-12-06 00:26:18,659 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=4777 sha256=0122f331053ae8eaff65dcfd60af2f3f93434948d63c677268b813a989ac8447\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-duynf0mz/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34m2019-12-06 00:26:19,768 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2019-12-06 00:26:19,778 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2019-12-06-00-23-18-098\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-23-18-098/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-23-18-098/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2019-12-06-00-23-18-098\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-23-18-098/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mReading input data\u001b[0m\n",
      "\u001b[34mTraining LR model\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\u001b[0m\n",
      "\u001b[34mSaving model to /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2019-12-06 00:26:22,511 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-12-06 00:26:34 Uploading - Uploading generated training model\n",
      "2019-12-06 00:26:34 Completed - Training job completed\n",
      "Training seconds: 54\n",
      "Billable seconds: 54\n"
     ]
    }
   ],
   "source": [
    "sklearn.fit({'train': preprocessed_training_data})\n",
    "training_job_description = sklearn.jobs[-1].describe()\n",
    "model_data_s3_uri = '{}{}/{}'.format(\n",
    "    training_job_description['OutputDataConfig']['S3OutputPath'],\n",
    "    training_job_description['TrainingJobName'],\n",
    "    'output/model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "`evaluation.py`는 모델 검증 스크립트입니다. 스크립트는 scikit-learn에 의존하여 실행되므로 이전에 작성한 `SKLearnProcessor`를 사용하여 실행하세요. 이 스크립트는 학습된 모델과 테스트 데이터셋를 입력으로 사용하고 각 레이블의 정밀도(precision), 재현도(recall) 및 F1 점수, 모델의 정확도(accuracy) 및 ROC AUC를 포함하여 분류 검증 지표들(classification evaluation metrics)이 포함된 JSON 파일을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile evaluation.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    model_path = os.path.join('/opt/ml/processing/model', 'model.tar.gz')\n",
    "    print('Extracting model from path: {}'.format(model_path))\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path='.')\n",
    "    print('Loading model')\n",
    "    model = joblib.load('model.joblib')\n",
    "\n",
    "    print('Loading test input data')\n",
    "    test_features_data = os.path.join('/opt/ml/processing/test', 'test_features.csv')\n",
    "    test_labels_data = os.path.join('/opt/ml/processing/test', 'test_labels.csv')\n",
    "\n",
    "    X_test = pd.read_csv(test_features_data, header=None)\n",
    "    y_test = pd.read_csv(test_labels_data, header=None)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    print('Creating classification evaluation report')\n",
    "    report_dict = classification_report(y_test, predictions, output_dict=True)\n",
    "    report_dict['accuracy'] = accuracy_score(y_test, predictions)\n",
    "    report_dict['roc_auc'] = roc_auc_score(y_test, predictions)\n",
    "\n",
    "    print('Classification report:\\n{}'.format(report_dict))\n",
    "\n",
    "    evaluation_output_path = os.path.join('/opt/ml/processing/evaluation', 'evaluation.json')\n",
    "    print('Saving classification report to {}'.format(evaluation_output_path))\n",
    "\n",
    "    with open(evaluation_output_path, 'w') as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2019-12-06-00-27-00-424\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-23-18-098/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-19-04-996/output/test_data', 'LocalPath': '/opt/ml/processing/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-27-00-424/input/code/evaluation.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'evaluation', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-scikit-learn-2019-12-06-00-27-00-424/output/evaluation', 'LocalPath': '/opt/ml/processing/evaluation', 'S3UploadMode': 'EndOfJob'}}]\n",
      "......................\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mExtracting model from path: /opt/ml/processing/model/model.tar.gz\u001b[0m\n",
      "\u001b[34mLoading model\u001b[0m\n",
      "\u001b[34mLoading test input data\u001b[0m\n",
      "\u001b[34mCreating classification evaluation report\u001b[0m\n",
      "\u001b[34mClassification report:\u001b[0m\n",
      "\u001b[34m{'0': {'precision': 0.9404501748251748, 'recall': 0.757191871206123, 'f1-score': 0.8389297724060626, 'support': 11367}, '1': {'precision': 0.3873473917869034, 'recall': 0.7620087336244541, 'f1-score': 0.5136129506990433, 'support': 2290}, 'micro avg': {'precision': 0.7579995606648605, 'recall': 0.7579995606648605, 'f1-score': 0.7579995606648605, 'support': 13657}, 'macro avg': {'precision': 0.6638987833060391, 'recall': 0.7596003024152885, 'f1-score': 0.676271361552553, 'support': 13657}, 'weighted avg': {'precision': 0.8477061334429062, 'recall': 0.7579995606648605, 'f1-score': 0.7843807849484165, 'support': 13657}, 'accuracy': 0.7579995606648605, 'roc_auc': 0.7596003024152885}\u001b[0m\n",
      "\u001b[34mSaving classification report to /opt/ml/processing/evaluation/evaluation.json\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "sklearn_processor.run(code='evaluation.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                                  source=model_data_s3_uri,\n",
    "                                  destination='/opt/ml/processing/model'),\n",
    "                              ProcessingInput(\n",
    "                                  source=preprocessed_test_data,\n",
    "                                  destination='/opt/ml/processing/test')],\n",
    "                      outputs=[ProcessingOutput(output_name='evaluation',\n",
    "                                  source='/opt/ml/processing/evaluation')]\n",
    "                     )                    \n",
    "evaluation_job_description = sklearn_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 검증 보고서(evaluation report)가 포함 된 Amazon S3에서 `evaluation.json` 파일을 검색하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": {\n",
      "        \"f1-score\": 0.8389297724060626,\n",
      "        \"precision\": 0.9404501748251748,\n",
      "        \"recall\": 0.757191871206123,\n",
      "        \"support\": 11367\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"f1-score\": 0.5136129506990433,\n",
      "        \"precision\": 0.3873473917869034,\n",
      "        \"recall\": 0.7620087336244541,\n",
      "        \"support\": 2290\n",
      "    },\n",
      "    \"accuracy\": 0.7579995606648605,\n",
      "    \"macro avg\": {\n",
      "        \"f1-score\": 0.676271361552553,\n",
      "        \"precision\": 0.6638987833060391,\n",
      "        \"recall\": 0.7596003024152885,\n",
      "        \"support\": 13657\n",
      "    },\n",
      "    \"micro avg\": {\n",
      "        \"f1-score\": 0.7579995606648605,\n",
      "        \"precision\": 0.7579995606648605,\n",
      "        \"recall\": 0.7579995606648605,\n",
      "        \"support\": 13657\n",
      "    },\n",
      "    \"roc_auc\": 0.7596003024152885,\n",
      "    \"weighted avg\": {\n",
      "        \"f1-score\": 0.7843807849484165,\n",
      "        \"precision\": 0.8477061334429062,\n",
      "        \"recall\": 0.7579995606648605,\n",
      "        \"support\": 13657\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "evaluation_output_config = evaluation_job_description['ProcessingOutputConfig']\n",
    "for output in evaluation_output_config['Outputs']:\n",
    "    if output['OutputName'] == 'evaluation':\n",
    "        evaluation_s3_uri = output['S3Output']['S3Uri'] + '/evaluation.json'\n",
    "        break\n",
    "\n",
    "evaluation_output = S3Downloader.read_file(evaluation_s3_uri)\n",
    "evaluation_output_dict = json.loads(evaluation_output)\n",
    "print(json.dumps(evaluation_output_dict, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running processing jobs with your own dependencies\n",
    "\n",
    "위에서 scikit-learn이 설치된 processing 컨테이너(container)를 사용했지만, processing 작업에서 사용자 정의 processing 컨테이너를 실행할 수 있으며 processing 컨테이너 내에서 실행할 스크립트를 계속 제공할 수 있습니다.\n",
    "\n",
    "아래에서는 processing 컨테이너를 만드는 방법과 `ScriptProcessor`를 사용하여 컨테이너 내에서 사용자 정의 코드(your own code)를 실행하는 방법에 대해 설명합니다. scikit-learn 컨테이너를 작성하고 위에서 사용한 것과 동일한 `preprocessing.py` 스크립트를 사용하여 처리 작업을 실행하세요. 여러분은 이 컨테이너 내에 사용자 정의 종속성을 제공하여 processing 스크립트를 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processing 컨테이너를 작성하는 Dockerfile을 작성합니다. 코드에서 `pandas`와 `scikit-learn`을 설치하는 것을 확인할 수 있습니다. 이와 같이 여러분이 필요한 의존성 패키지들(your own dependencies)을 자유롭게 설치할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing docker/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "\n",
    "FROM python:3.7-slim-buster\n",
    "\n",
    "RUN pip3 install pandas==0.25.3 scikit-learn==0.21.3\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "ENTRYPOINT [\"python3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드 블록은 `docker` 커맨드를 사용하여 컨테이너를 빌드하고 Amazon ECR(Amazon Elastic Container Registry) 리포지토리(repository)를 생성한 다음 이미지를 Amazon ECR로 push합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  2.048kB\n",
      "Step 1/4 : FROM python:3.7-slim-buster\n",
      "3.7-slim-buster: Pulling from library/python\n",
      "\n",
      "\u001b[1Bee12ec04: Pulling fs layer \n",
      "\u001b[1Bd83f8229: Pulling fs layer \n",
      "\u001b[1B0bee82a3: Pulling fs layer \n",
      "\u001b[1Bdcedfc84: Pulling fs layer \n",
      "\u001b[1B1cccc7f9: Pull complete 157MB/2.157MBB\u001b[3A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[KDigest: sha256:59af1bb7fb92ff97c9a23abae23f6beda13a95dbfd8100c7a2f71d150c0dc6e5\n",
      "Status: Downloaded newer image for python:3.7-slim-buster\n",
      " ---> 9f4008bf3f11\n",
      "Step 2/4 : RUN pip3 install pandas==0.25.3 scikit-learn==0.21.3\n",
      " ---> Running in 9d4660d08bdc\n",
      "Collecting pandas==0.25.3\n",
      "  Downloading https://files.pythonhosted.org/packages/63/e0/a1b39cdcb2c391f087a1538bc8a6d62a82d0439693192aef541d7b123769/pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
      "Collecting scikit-learn==0.21.3\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/c5/e5267eb84994e9a92a2c6a6ee768514f255d036f3c8378acfa694e9f2c99/scikit_learn-0.21.3-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n",
      "Collecting numpy>=1.13.3\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/af/4fc72f9d38e43b092e91e5b8cb9956d25b2e3ff8c75aed95df5569e4734e/numpy-1.17.4-cp37-cp37m-manylinux1_x86_64.whl (20.0MB)\n",
      "Collecting python-dateutil>=2.6.1\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/42/155696f85f344c066e17af287359c9786b436b1bf86029bb3411283274f3/joblib-0.14.0-py2.py3-none-any.whl (294kB)\n",
      "Collecting scipy>=0.17.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/18/f788042dc7a73d0176e073909c00a6765c953986cae6d8cc13782a4bcd05/scipy-1.3.3-cp37-cp37m-manylinux1_x86_64.whl (25.2MB)\n",
      "Collecting six>=1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, six, python-dateutil, pytz, pandas, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-0.14.0 numpy-1.17.4 pandas-0.25.3 python-dateutil-2.8.1 pytz-2019.3 scikit-learn-0.21.3 scipy-1.3.3 six-1.13.0\n",
      "Removing intermediate container 9d4660d08bdc\n",
      " ---> f044877b181f\n",
      "Step 3/4 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in 9e31bd463839\n",
      "Removing intermediate container 9e31bd463839\n",
      " ---> 3d740fab9667\n",
      "Step 4/4 : ENTRYPOINT [\"python3\"]\n",
      " ---> Running in 883064e2f0ef\n",
      "Removing intermediate container 883064e2f0ef\n",
      " ---> 54db6582c27f\n",
      "Successfully built 54db6582c27f\n",
      "Successfully tagged sagemaker-processing-container:latest\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws:ecr:us-east-1:143656149352:repository/sagemaker-processing-container\",\n",
      "        \"registryId\": \"143656149352\",\n",
      "        \"repositoryName\": \"sagemaker-processing-container\",\n",
      "        \"repositoryUri\": \"143656149352.dkr.ecr.us-east-1.amazonaws.com/sagemaker-processing-container\",\n",
      "        \"createdAt\": 1575592356.0,\n",
      "        \"imageTagMutability\": \"MUTABLE\",\n",
      "        \"imageScanningConfiguration\": {\n",
      "            \"scanOnPush\": false\n",
      "        }\n",
      "    }\n",
      "}\n",
      "The push refers to repository [143656149352.dkr.ecr.us-east-1.amazonaws.com/sagemaker-processing-container]\n",
      "\n",
      "\u001b[1B78547f9c: Preparing \n",
      "\u001b[1B1e895230: Preparing \n",
      "\u001b[1Ba4318145: Preparing \n",
      "\u001b[1Bb6fe98b7: Preparing \n",
      "\u001b[1B9d53a256: Preparing \n",
      "\u001b[6B78547f9c: Pushed   314.5MB/309.1MB\u001b[2A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[Klatest: digest: sha256:a1c4f841f42b13cf9d433fe621a70751a4443551b0b29ec3da80f7247fc4a272 size: 1583\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_repository = 'sagemaker-processing-container'\n",
    "tag = ':latest'\n",
    "processing_repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)\n",
    "\n",
    "# Create ECR repository and push docker image\n",
    "!docker build -t $ecr_repository docker\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ScriptProcessor` 클래스를 사용하면 이 컨테이너 내에서 명령을 실행할 수 있으며, 이 스크립트를 사용하여 여러분의 자체 스크립트(your own script)를 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor = ScriptProcessor(command=['python3'],\n",
    "                image_uri=processing_repository_uri,\n",
    "                role=role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 실행했던 것과 동일한 `preprocessing.py` 스크립트를 실행하지만, 이제 이 코드는 Amazon SageMaker가 유지 관리하는 scikit-learn 이미지가 아니라 이 노트북에서 빌드한 Docker 컨테이너 내에서 실행됩니다. Docker 이미지에 종속성을 추가하고 이 컨테이너 내에서 여러분이 자체 작성한 전처리, feature 엔지니어링 및 모델 검증 스크립트를 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-processing-container-2019-12-06-00-33-00-387\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-sample-data-us-east-1/processing/census/census-income.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-processing-container-2019-12-06-00-33-00-387/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-processing-container-2019-12-06-00-33-00-387/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-processing-container-2019-12-06-00-33-00-387/output/test_data', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      "........................\u001b[34mReceived arguments Namespace(train_test_split_ratio=0.2)\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/census-income.csv\u001b[0m\n",
      "\u001b[34mData after cleaning: (68285, 9), 11401 positive examples, 56884 negative examples\u001b[0m\n",
      "\u001b[34mSplitting data into train and test sets with ratio 0.2\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:778: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\u001b[0m\n",
      "\u001b[34mRunning preprocessing and feature engineering transformations\n",
      "  warnings.warn(message, DeprecationWarning)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\u001b[0m\n",
      "\u001b[34mTrain data shape after preprocessing: (54628, 69)\u001b[0m\n",
      "\u001b[34mTest data shape after preprocessing: (13657, 69)\u001b[0m\n",
      "\u001b[34mSaving training features to /opt/ml/processing/train/train_features.csv\u001b[0m\n",
      "\u001b[34mSaving test features to /opt/ml/processing/test/test_features.csv\u001b[0m\n",
      "\u001b[34mSaving training labels to /opt/ml/processing/train/train_labels.csv\u001b[0m\n",
      "\u001b[34mSaving test labels to /opt/ml/processing/test/test_labels.csv\u001b[0m\n",
      "\n",
      "{'ProcessingInputs': [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-sample-data-us-east-1/processing/census/census-income.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-processing-container-2019-12-06-00-33-00-387/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-processing-container-2019-12-06-00-33-00-387/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-143656149352/sagemaker-processing-container-2019-12-06-00-33-00-387/output/test_data', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]}, 'ProcessingJobName': 'sagemaker-processing-container-2019-12-06-00-33-00-387', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '143656149352.dkr.ecr.us-east-1.amazonaws.com/sagemaker-processing-container:latest', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/preprocessing.py'], 'ContainerArguments': ['--train-test-split-ratio', '0.2']}, 'RoleArn': 'arn:aws:iam::143656149352:role/service-role/AmazonSageMaker-ExecutionRole-20191206T081784', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:143656149352:processing-job/sagemaker-processing-container-2019-12-06-00-33-00-387', 'ProcessingJobStatus': 'Completed', 'ProcessingEndTime': datetime.datetime(2019, 12, 6, 0, 37, 4, tzinfo=tzlocal()), 'ProcessingStartTime': datetime.datetime(2019, 12, 6, 0, 34, 53, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2019, 12, 6, 0, 37, 4, 100000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2019, 12, 6, 0, 33, 0, 718000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': 'c637133f-7fb1-4e64-b715-6657d17723e8', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'c637133f-7fb1-4e64-b715-6657d17723e8', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2005', 'date': 'Fri, 06 Dec 2019 00:37:42 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "script_processor.run(code='preprocessing.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=input_data,\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train'),\n",
    "                               ProcessingOutput(output_name='test_data',\n",
    "                                                source='/opt/ml/processing/test')],\n",
    "                      arguments=['--train-test-split-ratio', '0.2']\n",
    "                     )\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
