{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with Amazon SageMaker for molecular property prediction\n",
    "\n",
    "*이 노트북은 [Hyperparameter tuning with Amazon SageMaker for molecular property prediction (영문 원본)](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/dgl_gcn_tox21/pytorch-gcn-tox21-hypertune.ipynb) 의 한국어 번역입니다.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](##Background)  \n",
    "2. [Setup](##Setup)  \n",
    "3. [Code](##Code)  \n",
    "4. [Tune](##Tune)  \n",
    "5. [Wrap-up](##Wrap-up)  \n",
    "\n",
    "## Background\n",
    "\n",
    "이 예제 노트북은 자동 하이퍼파라미터 튜닝을 사용한 그래프 기반 분자 특성 예측 모델(graph-based molecular property prediction model)을 보여줍니다. 구현은 DGL 및 PyTorch를 기반으로 합니다. 최고의 하이퍼파라미터를 찾기 위해 SageMaker를 활용하여 다른 하이퍼파라미터 조합으로 여러 학습 작업들을 시작합니다. 이 예제에서는 [Amazon SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)를 사용하여 하이퍼파라미터 튜닝 작업을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "이 노트북은 ml.p3.2xlarge 노트북 인스턴스에서 작성 및 테스트되었습니다.\n",
    "\n",
    "선수 조건\n",
    " * 이 튜토리얼을 시작하기 전에 `pytorch-gcn-tox21.ipynb`을 검토하고 여러분 계정의 Amazon Elastic Container Registry(Amazon ECR)에\n",
    " \\{account\\}.dkr.ecr.\\{region\\}.amazonaws.com/sagemaker-dgl-pytorch-gcn-tox21:latest 가 있는지 확인하세요.\n",
    " * 학습 및 모델 데이터에 사용할 S3 버킷 및 접두사(prefix)를 확인하세요. S3는 노트북 인스턴스, 학습 및 호스팅과 동일한 리전 내에 있어야합니다.\n",
    " * 학습 및 호스팅 데이터 액세스를 제공하는 데 사용할 IAM 역할(role) ARN을 확인합니다. IAM 역할 생성에 대한 자세한 내용은 설명서를 참조하세요. 역할이 현재 노트북 인스턴스와 연결되어 있지 않거나 학습 및 호스팅에 둘 이상의 역할이 필요한 경우 `sagemaker.get_execution_role()`을 적절한 전체 IAM 역할 ARN 문자열로 바꿔야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# Setup session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Location to put your custom code.\n",
    "custom_code_upload_location = 'customcode'\n",
    "\n",
    "# IAM execution role that gives Amazon SageMaker access to resources in your AWS account.\n",
    "# Use the Amazon SageMaker Python SDK to get the role from the notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Amazon SageMaker와 함께 Docker 컨테이너를 실행하려면 컨테이너를 실행할 Python 스크립트를 제공해야 합니다. 이 예제에서 `main.py`는 Amazon SageMaker 모델을 학습하는 데 필요한 모든 코드를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mdgl\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatetime\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datetime\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdgl\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m model_zoo\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdgl.data.chem\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Tox21\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdgl.data.utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m split_dataset\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.metrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m roc_auc_score\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BCEWithLogitsLoss\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch.optim\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Adam\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch.utils.data\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataLoader\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msetup\u001b[39;49;00m(args, seed=\u001b[34m0\u001b[39;49;00m):\n",
      "    args[\u001b[33m'\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# Set random seed\u001b[39;49;00m\n",
      "    random.seed(seed)\n",
      "    np.random.seed(seed)\n",
      "    torch.manual_seed(seed)\n",
      "    \u001b[34mif\u001b[39;49;00m torch.cuda.is_available():\n",
      "        torch.cuda.manual_seed(seed)\n",
      "    \u001b[34mreturn\u001b[39;49;00m args\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcollate_molgraphs\u001b[39;49;00m(data):\n",
      "    \u001b[33m\"\"\"Batching a list of datapoints for dataloader.\"\"\"\u001b[39;49;00m\n",
      "    smiles, graphs, labels, masks = \u001b[36mmap\u001b[39;49;00m(\u001b[36mlist\u001b[39;49;00m, \u001b[36mzip\u001b[39;49;00m(*data))\n",
      "\n",
      "    bg = dgl.batch(graphs)\n",
      "    bg.set_n_initializer(dgl.init.zero_initializer)\n",
      "    bg.set_e_initializer(dgl.init.zero_initializer)\n",
      "    labels = torch.stack(labels, dim=\u001b[34m0\u001b[39;49;00m)\n",
      "    masks = torch.stack(masks, dim=\u001b[34m0\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m smiles, bg, labels, masks\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mEarlyStopper\u001b[39;49;00m(\u001b[36mobject\u001b[39;49;00m):\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, patience, filename=\u001b[36mNone\u001b[39;49;00m):\n",
      "        \u001b[34mif\u001b[39;49;00m filename \u001b[35mis\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m:\n",
      "            \u001b[37m# Name checkpoint based on time\u001b[39;49;00m\n",
      "            dt = datetime.now()\n",
      "            filename = \u001b[33m'\u001b[39;49;00m\u001b[33mearly_stop_{}_{:02d}-{:02d}-{:02d}.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "                dt.date(), dt.hour, dt.minute, dt.second)\n",
      "            filename = os.path.join(\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, filename)\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.patience = patience\n",
      "        \u001b[36mself\u001b[39;49;00m.counter = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.filename = filename\n",
      "        \u001b[36mself\u001b[39;49;00m.best_score = \u001b[36mNone\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.early_stop = \u001b[36mFalse\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msave_checkpoint\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, model):\n",
      "        \u001b[33m'''Saves model when the metric on the validation set gets improved.'''\u001b[39;49;00m\n",
      "        torch.save({\u001b[33m'\u001b[39;49;00m\u001b[33mmodel_state_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.state_dict()}, \u001b[36mself\u001b[39;49;00m.filename)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mload_checkpoint\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, model):\n",
      "        \u001b[33m'''Load model saved with early stopping.'''\u001b[39;49;00m\n",
      "        model.load_state_dict(torch.load(\u001b[36mself\u001b[39;49;00m.filename)[\u001b[33m'\u001b[39;49;00m\u001b[33mmodel_state_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mstep\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, score, model):\n",
      "        \u001b[34mif\u001b[39;49;00m (\u001b[36mself\u001b[39;49;00m.best_score \u001b[35mis\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m) \u001b[35mor\u001b[39;49;00m (score > \u001b[36mself\u001b[39;49;00m.best_score):\n",
      "            \u001b[36mself\u001b[39;49;00m.best_score = score\n",
      "            \u001b[36mself\u001b[39;49;00m.save_checkpoint(model)\n",
      "            \u001b[36mself\u001b[39;49;00m.counter = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            \u001b[36mself\u001b[39;49;00m.counter += \u001b[34m1\u001b[39;49;00m\n",
      "            \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mEarlyStopping counter: {:d} out of {:d}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[36mself\u001b[39;49;00m.counter, \u001b[36mself\u001b[39;49;00m.patience))\n",
      "            \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.counter >= \u001b[36mself\u001b[39;49;00m.patience:\n",
      "                \u001b[36mself\u001b[39;49;00m.early_stop = \u001b[36mTrue\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.early_stop\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mMeter\u001b[39;49;00m(\u001b[36mobject\u001b[39;49;00m):\n",
      "    \u001b[33m\"\"\"Track and summarize model performance on a dataset for\u001b[39;49;00m\n",
      "\u001b[33m    (multi-label) binary classification.\"\"\"\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[36mself\u001b[39;49;00m.mask = []\n",
      "        \u001b[36mself\u001b[39;49;00m.y_pred = []\n",
      "        \u001b[36mself\u001b[39;49;00m.y_true = []\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mupdate\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, y_pred, y_true, mask):\n",
      "        \u001b[33m\"\"\"Update for the result of an iteration\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m        Parameters\u001b[39;49;00m\n",
      "\u001b[33m        ----------\u001b[39;49;00m\n",
      "\u001b[33m        y_pred : float32 tensor\u001b[39;49;00m\n",
      "\u001b[33m            Predicted molecule labels with shape (B, T),\u001b[39;49;00m\n",
      "\u001b[33m            B for batch size and T for the number of tasks\u001b[39;49;00m\n",
      "\u001b[33m        y_true : float32 tensor\u001b[39;49;00m\n",
      "\u001b[33m            Ground truth molecule labels with shape (B, T)\u001b[39;49;00m\n",
      "\u001b[33m        mask : float32 tensor\u001b[39;49;00m\n",
      "\u001b[33m            Mask for indicating the existence of ground\u001b[39;49;00m\n",
      "\u001b[33m            truth labels with shape (B, T)\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.y_pred.append(y_pred.detach().cpu())\n",
      "        \u001b[36mself\u001b[39;49;00m.y_true.append(y_true.detach().cpu())\n",
      "        \u001b[36mself\u001b[39;49;00m.mask.append(mask.detach().cpu())\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mroc_auc_score\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[33m\"\"\"Compute roc-auc score for each task.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m        Returns\u001b[39;49;00m\n",
      "\u001b[33m        -------\u001b[39;49;00m\n",
      "\u001b[33m        list of float\u001b[39;49;00m\n",
      "\u001b[33m            roc-auc score for all tasks\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\n",
      "        mask = torch.cat(\u001b[36mself\u001b[39;49;00m.mask, dim=\u001b[34m0\u001b[39;49;00m)\n",
      "        y_pred = torch.cat(\u001b[36mself\u001b[39;49;00m.y_pred, dim=\u001b[34m0\u001b[39;49;00m)\n",
      "        y_true = torch.cat(\u001b[36mself\u001b[39;49;00m.y_true, dim=\u001b[34m0\u001b[39;49;00m)\n",
      "        \u001b[37m# This assumes binary case only\u001b[39;49;00m\n",
      "        y_pred = torch.sigmoid(y_pred)\n",
      "        n_tasks = y_true.shape[\u001b[34m1\u001b[39;49;00m]\n",
      "        scores = []\n",
      "        \u001b[34mfor\u001b[39;49;00m task \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_tasks):\n",
      "            task_w = mask[:, task]\n",
      "            task_y_true = y_true[:, task][task_w != \u001b[34m0\u001b[39;49;00m].numpy()\n",
      "            task_y_pred = y_pred[:, task][task_w != \u001b[34m0\u001b[39;49;00m].numpy()\n",
      "            scores.append(roc_auc_score(task_y_true, task_y_pred))\n",
      "        \u001b[34mreturn\u001b[39;49;00m scores\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mrun_a_train_epoch\u001b[39;49;00m(args, epoch, model, data_loader, loss_criterion, optimizer):\n",
      "    model.train()\n",
      "    train_meter = Meter()\n",
      "    \u001b[34mfor\u001b[39;49;00m batch_id, batch_data \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(data_loader):\n",
      "        smiles, bg, labels, masks = batch_data\n",
      "        atom_feats = bg.ndata.pop(args[\u001b[33m'\u001b[39;49;00m\u001b[33matom_data_field\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "        atom_feats, labels, masks = atom_feats.to(args[\u001b[33m'\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), \\\n",
      "                                    labels.to(args[\u001b[33m'\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), \\\n",
      "                                    masks.to(args[\u001b[33m'\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "        logits = model(bg, atom_feats)\n",
      "        \u001b[37m# Mask non-existing labels\u001b[39;49;00m\n",
      "        loss = (loss_criterion(logits, labels) * (masks != \u001b[34m0\u001b[39;49;00m).float()).mean()\n",
      "        optimizer.zero_grad()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mepoch {:d}/{:d}, batch {:d}/{:d}, loss {:.4f}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "            epoch + \u001b[34m1\u001b[39;49;00m, args[\u001b[33m'\u001b[39;49;00m\u001b[33mn_epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_id + \u001b[34m1\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(data_loader), loss.item()))\n",
      "        train_meter.update(logits, labels, masks)\n",
      "    train_score = np.mean(train_meter.roc_auc_score())\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mepoch {:d}/{:d}, training roc-auc {:.4f}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "        epoch + \u001b[34m1\u001b[39;49;00m, args[\u001b[33m'\u001b[39;49;00m\u001b[33mn_epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], train_score))\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mrun_an_eval_epoch\u001b[39;49;00m(args, model, data_loader):\n",
      "    model.eval()\n",
      "    eval_meter = Meter()\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_id, batch_data \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(data_loader):\n",
      "            smiles, bg, labels, masks = batch_data\n",
      "            atom_feats = bg.ndata.pop(args[\u001b[33m'\u001b[39;49;00m\u001b[33matom_data_field\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "            atom_feats, labels = atom_feats.to(args[\u001b[33m'\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), labels.to(args[\u001b[33m'\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "            logits = model(bg, atom_feats)\n",
      "            eval_meter.update(logits, labels, masks)\n",
      "    \u001b[34mreturn\u001b[39;49;00m np.mean(eval_meter.roc_auc_score())\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mload_sagemaker_config\u001b[39;49;00m(args):\n",
      "    file_path = \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/input/config/hyperparameters.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m os.path.isfile(file_path):\n",
      "        \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(file_path, \u001b[33m'\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "            new_args = json.load(f)\n",
      "            \u001b[34mfor\u001b[39;49;00m k, v \u001b[35min\u001b[39;49;00m new_args.items():\n",
      "                \u001b[34mif\u001b[39;49;00m k \u001b[35mnot\u001b[39;49;00m \u001b[35min\u001b[39;49;00m args:\n",
      "                    \u001b[34mcontinue\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(args[k], \u001b[36mint\u001b[39;49;00m):\n",
      "                    v = \u001b[36mint\u001b[39;49;00m(v)\n",
      "                \u001b[34mif\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(args[k], \u001b[36mfloat\u001b[39;49;00m):\n",
      "                    v = \u001b[36mfloat\u001b[39;49;00m(v)\n",
      "                args[k] = v\n",
      "    \u001b[34mreturn\u001b[39;49;00m args\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m(args):\n",
      "    args = setup(args)\n",
      "\n",
      "    dataset = Tox21()\n",
      "    train_set, val_set, test_set = split_dataset(dataset, shuffle=\u001b[36mTrue\u001b[39;49;00m)\n",
      "    train_loader = DataLoader(train_set, batch_size=args[\u001b[33m'\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                              shuffle=\u001b[36mTrue\u001b[39;49;00m, collate_fn=collate_molgraphs)\n",
      "    val_loader = DataLoader(val_set, batch_size=args[\u001b[33m'\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                            shuffle=\u001b[36mTrue\u001b[39;49;00m, collate_fn=collate_molgraphs)\n",
      "    test_loader = DataLoader(test_set, batch_size=args[\u001b[33m'\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                             shuffle=\u001b[36mTrue\u001b[39;49;00m, collate_fn=collate_molgraphs)\n",
      "\n",
      "    model = model_zoo.chem.GCNClassifier(\n",
      "        in_feats=args[\u001b[33m'\u001b[39;49;00m\u001b[33mn_input\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "        gcn_hidden_feats=[args[\u001b[33m'\u001b[39;49;00m\u001b[33mn_hidden\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] \u001b[34mfor\u001b[39;49;00m _ \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(args[\u001b[33m'\u001b[39;49;00m\u001b[33mn_layers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])],\n",
      "        n_tasks=dataset.n_tasks,\n",
      "        classifier_hidden_feats=args[\u001b[33m'\u001b[39;49;00m\u001b[33mn_hidden\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).to(args[\u001b[33m'\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    loss_criterion = BCEWithLogitsLoss(\n",
      "        pos_weight=torch.tensor(dataset.task_pos_weights).to(args[\u001b[33m'\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), reduction=\u001b[33m'\u001b[39;49;00m\u001b[33mnone\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    optimizer = Adam(model.parameters(), lr=args[\u001b[33m'\u001b[39;49;00m\u001b[33mlr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    stopper = EarlyStopper(args[\u001b[33m'\u001b[39;49;00m\u001b[33mpatience\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(args[\u001b[33m'\u001b[39;49;00m\u001b[33mn_epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]):\n",
      "        \u001b[37m# Train\u001b[39;49;00m\n",
      "        run_a_train_epoch(args, epoch, model, train_loader, loss_criterion, optimizer)\n",
      "\n",
      "        \u001b[37m# Validation and early stop\u001b[39;49;00m\n",
      "        val_score = run_an_eval_epoch(args, model, val_loader)\n",
      "        early_stop = stopper.step(val_score, model)\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mepoch {:d}/{:d}, validation roc-auc {:.4f}, best validation roc-auc {:.4f}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "            epoch + \u001b[34m1\u001b[39;49;00m, args[\u001b[33m'\u001b[39;49;00m\u001b[33mn_epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], val_score, stopper.best_score))\n",
      "        \u001b[34mif\u001b[39;49;00m early_stop:\n",
      "            \u001b[34mbreak\u001b[39;49;00m\n",
      "\n",
      "    stopper.load_checkpoint(model)\n",
      "    test_score = run_an_eval_epoch(args, model, test_loader)\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mBest validation score {:.4f}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(stopper.best_score))\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mTest score {:.4f}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(test_score))\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\n",
      "    parser = argparse.ArgumentParser(description=\u001b[33m'\u001b[39;49;00m\u001b[33mGCN for Tox21\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m128\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mNumber of graphs (molecules) per batch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m1e-3\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mLearning rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n-epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mMaximum number of training epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--atom-data-field\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mh\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mName for storing atom features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n-input\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m74\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mSize for input atom features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n-hidden\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mSize for hidden representations\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n-layers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mNumber of hidden layers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--patience\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mNumber of epochs to wait before early stop\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_args().\u001b[31m__dict__\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    args = parse_args()\n",
      "    args = load_sagemaker_config(args)\n",
      "    main(args)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune\n",
    "Amazon SageMaker에서 단일 학습 작업을 학습하는 것과 유사하게 코드 스크립트, IAM 역할, (작업별) 하드웨어 설정 및 아직 튜닝하지 않은 하이퍼파라미터를 전달하는 학습 estimator를 정의합니다.\n",
    "\n",
    "`pytorch-gcn-tox21.ipynb`에서 생성한 Amazon Elastic Container Registry(Amazon ECR)에 Docker 이미지가 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target dgl-docker name\n",
    "docker_name='sagemaker-dgl-pytorch-gcn-tox21'\n",
    "\n",
    "CODE_PATH = 'main.py'\n",
    "code_location = sess.upload_data(CODE_PATH, bucket=bucket, key_prefix=custom_code_upload_location)\n",
    "\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, docker_name)\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(image,\n",
    "                                          role, \n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.p3.2xlarge',\n",
    "                                          hyperparameters={'entrypoint': CODE_PATH},\n",
    "                                          sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator 객체를 정의한 후, 조정하려는 하이퍼파라미터와 가능한 값들을 지정하세요. 가능한 값들의 유형에 따라 하이퍼파라미터는 세 가지 클래스로 나눌 수 있습니다.\n",
    "\n",
    "* **범주형(Categorical)**:: 가능한 범주값들로 이산(discrete) 셋을 구성하며 `CategoricalParameter(list)`로 표시됩니다.\n",
    "* **연속형(Continuous)** : `[min, max]` 간격 내에서 임의의 실수를 사용할 수 있으며, `ContinuousParameter(min, max)`로 표시됩니다.\n",
    "* **정수형(Integer)**: `[min, max]` 간격 내에서 정수 값을 사용할 수 있으며 `IntegerParameter (min, max)`로 표시됩니다.\n",
    "\n",
    "값을 최소 제한 유형(least restrictive type)으로 지정하는 것이 대부분 좋습니다. 예를 들어 `ContinuousParameter(0.01, 0.2)`는 `CategoricalParameter([0.01, 0.1, 0.15, 0.2])`보다 덜 제한적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter\n",
    "\n",
    "hyper_ranges = {'lr': ContinuousParameter(1e-4, 1e-2),\n",
    "                'patience': IntegerParameter(5, 30),\n",
    "                'n_hidden': CategoricalParameter([32, 64, 128])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 튜닝할 목표 지표(metric)와 지표에 대한 정의를 지정하십시오. 여기에는 학습 작업의 Amazon CloudWatch 로그에서 해당 지표를 추출하는 데 필요한 정규식(regex)이 포함됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_name = 'Validation_roc_auc'\n",
    "metric_definitions = [{'Name': objective_name,\n",
    "                       'Regex': 'Best validation score ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `HyperparameterTuner` 객체를 생성하겠습니다. 해당 객체의 인자값에는 아래와 같은 값들이 포함되어야 합니다.\n",
    "\n",
    "* 위에서 생성한 학습 estimator\n",
    "* 하이퍼파라미터 범위\n",
    "* 목표 지표 이름 및 정의\n",
    "* 총 학습 작업 수와 동시에 실행해야 하는 학습 작업 수; 병렬 작업이 많을수록 튜닝이 더 빨리 완료되지만 정확도(accuracy)가 떨어질 수 있습니다. 병렬 작업 값을 총 학습 작업 수의 10% 미만으로 설정하는 것이 좋습니다. 이 예제에서는 빠르게 실행하기 위해 동시 학습 작업 수가 높게 설정되어 있습니다.\n",
    "* 목표 지표을 최대화해야하는지 또는 최소화해야하는지 여부(Maximize or Minimize); 기본값이 'Maximize'이고 이 예제에서는 roc-auc를 최대화하는 것이기 때문에 기본값을 지정하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_name,\n",
    "                            hyper_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=6,\n",
    "                            max_parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 `.fit()`을 호출하여 튜닝 작업을 시작하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(inputs={'training-code': code_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터 튜닝 작업 상태를 점검하여 성공적으로 시작되었고 진행 중(InProgress)인지 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InProgress'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "하이퍼파라미터 튜닝 작업이 시작된 후, 백그라운드에서 실행되며 이 노트북을 닫을 수 있습니다. 완료되면 콘솔로 이동하여 결과를 분석할 수 있습니다.\n",
    "\n",
    "Amazon SageMaker의 하이퍼파라메터 튜닝에 대한 자세한 내용은 AWS 설명서를 참조하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
